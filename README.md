# prompt-safety-agent
Classifying text prompts as safe or unsafe using a local LLM
