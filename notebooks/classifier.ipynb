{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1300efc",
   "metadata": {},
   "source": [
    "# Classifier\n",
    "\n",
    "The goal of this notebook is to train and evaluate a simple baseline classifier for the problem of unsafe prompt detection. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd40c4d",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "In this section, we will install the dependencies required to run the code in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4767bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add project root to path\n",
    "sys.path.append(os.path.abspath(\"..\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763317de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.dataset import get_project_dataset\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from datasets.arrow_dataset import Column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc40fb3d",
   "metadata": {},
   "source": [
    "## Model training\n",
    "\n",
    "In this section, we train a "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de888c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = get_project_dataset()\n",
    "\n",
    "X_train, y_train = dataset[\"train\"][\"text\"], dataset[\"train\"][\"label\"]\n",
    "X_test, y_test = dataset[\"test\"][\"text\"], dataset[\"test\"][\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19b0af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pipeline that first converts raw text into TF-IDF vectors,\n",
    "#  then trains a logistic regression classifier on those vectors.\n",
    "clf = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer()), \n",
    "    (\"logreg\", LogisticRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b72f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390950c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_classifier(\n",
    "    model: Pipeline,\n",
    "    X_train: Column,\n",
    "    y_train: Column,\n",
    "    X_test: Column,\n",
    "    y_test: Column,\n",
    "    digits: int = 4\n",
    ") -> None:\n",
    "    \"\"\"Evaluate and print classification reports for train and test sets.\"\"\"\n",
    "\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    print(\"--- Train set ---\")\n",
    "    print(classification_report(y_train, y_train_pred, digits=digits))\n",
    "    \n",
    "    y_test_pred = model.predict(X_test)\n",
    "    print(\"--- Test set ---\")\n",
    "    print(classification_report(y_test, y_test_pred, digits=digits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0d4ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_classifier(model=clf, X_train=X_train, y_train=y_train, X_test=X_test, y_test=y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2511e0",
   "metadata": {},
   "source": [
    "This is a very strong baseline. Due to the similiatiy between train and test matrix metrics, no meaninful overfitting of the training data.\n",
    "\n",
    "For safety applications, we should try and push recall for unsafe prompts higher, even if it costs some precision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e58e84",
   "metadata": {},
   "source": [
    "## Weight tuning\n",
    "\n",
    "In our dataset exploration, we found a class imbalance: approximately 70% of examples are safe prompts, while only 30% are unsafe. This imbalance is also need in the 'support' column classification report. In this section, we try to increase recall for unsafe prompts by tuning class weights, to assign more importance to the unsafe classe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca45c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To address the 70/30 class imbalance, let's adjusts weights inversely proportional to class frequencies\n",
    "clf = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer()), \n",
    "    (\"logreg\", LogisticRegression(class_weight=\"balanced\"))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf92872",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8d5dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_classifier(model=clf, X_train=X_train, y_train=y_train, X_test=X_test, y_test=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a54819",
   "metadata": {},
   "source": [
    "Giving fair importance to all classes leads to a more robust and accurate model, let's further explore for custom weightings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28114a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(\n",
    "    X_train: Column,\n",
    "    y_train: Column,\n",
    "    X_test: Column,\n",
    "    y_test: Column,\n",
    "    class_weights: dict[int, float],\n",
    "    digits: int = 4\n",
    ") -> None:\n",
    "    \"\"\"Train and evaluate logistic regression with given class weights.\"\"\"\n",
    "\n",
    "    clf = Pipeline([\n",
    "        (\"tfidf\", TfidfVectorizer()),\n",
    "        (\"logreg\", LogisticRegression(class_weight=class_weights))\n",
    "    ])\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    evaluate_classifier(\n",
    "        model=clf,\n",
    "        X_train=X_train,\n",
    "        y_train=y_train,\n",
    "        X_test=X_test,\n",
    "        y_test=y_test,\n",
    "        digits=digits,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c222424",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights={0: 1, 1: 5}\n",
    "train_and_evaluate(X_train=X_train, y_train=y_train, X_test=X_test, y_test=y_test, class_weights=class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14482fd",
   "metadata": {},
   "source": [
    "A weighting ratio of about `1:5` is the maximum before recall stops improving and precision and accuracy begin to decline."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
